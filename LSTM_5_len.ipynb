{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_5_len.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1iqlnmPiatT7PaxTO6BUUQA-fUAb4h99i",
      "authorship_tag": "ABX9TyNU2m+Fe+kwPtSyqDgcYtuX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zahraDehghanian97/LSTM_sequence_prediction/blob/master/LSTM_5_len.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTSvl-QYjyo3"
      },
      "source": [
        "# **prerequisit**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2F_EIyczeua"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense , LSTM , Dropout , Masking\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.backend import clear_session \n",
        "from tensorflow.keras.callbacks import ModelCheckpoint , EarlyStopping\n",
        "from dataclasses import make_dataclass\n",
        "import keras\n",
        "# constant\n",
        "num_class = 7736\n",
        "dimension = 1\n",
        "seq_len = 5"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tmrWx7z1Uce"
      },
      "source": [
        "# **load data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ja4SgpL1ZCY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0becb0d-13d8-4641-9f7c-8ea575f43413"
      },
      "source": [
        "\n",
        "data_train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/predict_next_game/train_Copy.csv')\n",
        "X = []\n",
        "y = []\n",
        "seq_lens = []\n",
        "seq_lens_test = []\n",
        "\n",
        "for d in data_train.values:\n",
        "    temp = []\n",
        "    for t in d[1].split(\" \"):\n",
        "        temp.append(int(t))\n",
        "    X.append((temp))\n",
        "    y.append( d[2])\n",
        "    seq_lens.append(len(temp))\n",
        "\n",
        "data_test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/predict_next_game/test.csv')\n",
        "x_test = []\n",
        "index_test = []\n",
        "for d in data_test.values:\n",
        "    index_test.append(d[0])\n",
        "    temp = []\n",
        "    for t in d[1].split(\" \"):\n",
        "        temp.append(int(t))\n",
        "    x_test.append((temp))\n",
        "    seq_lens_test.append(len(temp))\n",
        "    \n",
        "print(len(seq_lens))\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "499\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CzSUDzMMMEr"
      },
      "source": [
        "# **convert to min size sequence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W69alga3doKp",
        "outputId": "4392ccda-df5d-4b72-de99-afeda81e1ade"
      },
      "source": [
        "X_test =np.full((len(seq_lens_test), seq_len, dimension), fill_value=0)\n",
        "size_train = np.sum(seq_lens) - ((seq_len-1) * len(seq_lens) )\n",
        "size_train += np.sum(seq_lens_test) - ((seq_len) * len(seq_lens_test))\n",
        "X_train = np.full((size_train, seq_len, dimension), fill_value=0)\n",
        "Y_train = np.full(size_train,fill_value=0)\n",
        "\n",
        "# make train data in shape of array with len = seq_len\n",
        "counter = 0\n",
        "for i in range(len(seq_lens)):\n",
        "  for j in range(seq_lens[i]-seq_len+1):\n",
        "    xx = np.array(X[i][j:j+seq_len])\n",
        "    X_train[counter, :, :] = xx.reshape(seq_len,1)\n",
        "    if j == seq_lens[i]-seq_len  :\n",
        "      Y_train[counter] = y[i]\n",
        "    else :\n",
        "      Y_train[counter] = (X[i][j+seq_len])\n",
        "    counter +=1\n",
        "\n",
        "# make tesr data in shape of array with len = seq_len\n",
        "## note : use additional test data to improve training\n",
        "counter_test = 0\n",
        "for i in range(len(seq_lens_test)):\n",
        "  for j in range(seq_lens_test[i]-seq_len+1):\n",
        "    if j == seq_lens_test[i]-seq_len  :\n",
        "      xx = np.array(np.array(x_test[i][j:j+seq_len]))\n",
        "      X_test[counter_test, :, :] = xx.reshape(seq_len,1)\n",
        "      counter_test += 1\n",
        "    else :\n",
        "      xx = np.array(x_test[i][j:j+seq_len])\n",
        "      X_train[counter, :, :] = xx.reshape(seq_len,1)\n",
        "      Y_train[counter] = (x_test[i][j+seq_len])\n",
        "      counter += 1\n",
        "      \n",
        "# split validation data\n",
        "validation = True\n",
        "if validation :\n",
        "  X_validation = X_train[:200]\n",
        "  X_train = X_train[200:]\n",
        "  Y_validation = Y_train[:200]\n",
        "  Y_train = Y_train[200:]\n",
        "\n",
        "  \n",
        "print(np.isnan(X_train).any())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 118]\n",
            " [3135]\n",
            " [ 683]\n",
            " [ 213]\n",
            " [ 298]]\n",
            "[[   3]\n",
            " [  12]\n",
            " [ 262]\n",
            " [6094]\n",
            " [ 283]]\n",
            "50\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Cr7eV2CQdqH"
      },
      "source": [
        "# **LSTM Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbGA9PV1QoUI",
        "outputId": "26282224-17b9-44db-935f-1a06deba0f56"
      },
      "source": [
        "clear_session()\n",
        "lstm_units = seq_len * 4\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(lstm_units, return_sequences=True, input_shape=(seq_len,dimension)))\n",
        "# model.add(Dropout(rate=0.3))\n",
        "model.add(LSTM(lstm_units, return_sequences=True))\n",
        "# model.add(Dropout(rate=0.3))\n",
        "# model.add(LSTM(lstm_units, return_sequences=True))\n",
        "# model.add(Dropout(rate=0.3))\n",
        "model.add(LSTM(lstm_units))\n",
        "# model.add(Dropout(rate=0.2))\n",
        "# model.add(Dense(units=2 * num_class, activation='relu'))\n",
        "model.add(Dense(units=num_class, activation='softmax'))\n",
        "print(model.summary())\n",
        "\n",
        "filepath1=\"/content/drive/MyDrive/Colab Notebooks/predict_next_game/weights.hdf5\"\n",
        "filepath2=\"/content/drive/MyDrive/Colab Notebooks/predict_next_game/weights2.hdf5\"\n",
        "# load the trained LSTM model\n",
        "model.load_weights(filepath1)\n",
        "print(\"load saved model\")\n",
        "\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath2, monitor='val_loss', verbose=1, save_best_only=True, mode='max')\n",
        "# earlyStop = EarlyStopping(monitor='val_loss', patience=5)\n",
        "# model.compile(optimizer = 'rmsprop', loss = 'mean_squared_error')\n",
        "# model.fit(X_train,Y_train, epochs = 150,validation_split=0.01, batch_size =16,callbacks=[checkpoint,earlyStop])\n",
        "\n",
        "# callbacks\n",
        "checkpoint = ModelCheckpoint(filepath2, monitor='val_sparse_top_k_categorical_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "earlyStop = EarlyStopping(monitor='val_sparse_top_k_categorical_accuracy', patience=5)\n",
        "# Fit the model\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001), loss=SparseCategoricalCrossentropy(), metrics=['sparse_top_k_categorical_accuracy'])\n",
        "history = model.fit(X_train, Y_train, epochs=150,batch_size = 16,validation_split = 0.1,callbacks=[checkpoint,earlyStop])\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 5, 20)             1760      \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 5, 20)             3280      \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 20)                3280      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 7736)              162456    \n",
            "=================================================================\n",
            "Total params: 170,776\n",
            "Trainable params: 170,776\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "load saved model\n",
            "Epoch 1/150\n",
            "3812/3812 [==============================] - 76s 6ms/step - loss: 3163430.0000 - val_loss: 2945074.5000\n",
            "\n",
            "Epoch 00001: val_loss improved from -inf to 2945074.50000, saving model to /content/drive/MyDrive/Colab Notebooks/predict_next_game/weights2.hdf5\n",
            "Epoch 2/150\n",
            "3812/3812 [==============================] - 20s 5ms/step - loss: 3163423.0000 - val_loss: 2945074.5000\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 2945074.50000\n",
            "Epoch 3/150\n",
            "3812/3812 [==============================] - 20s 5ms/step - loss: 3163428.0000 - val_loss: 2945074.5000\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 2945074.50000\n",
            "Epoch 4/150\n",
            "3812/3812 [==============================] - 20s 5ms/step - loss: 3163429.2500 - val_loss: 2945074.5000\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 2945074.50000\n",
            "Epoch 5/150\n",
            "3812/3812 [==============================] - 20s 5ms/step - loss: 3163427.0000 - val_loss: 2945074.5000\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 2945074.50000\n",
            "Epoch 6/150\n",
            "3812/3812 [==============================] - 20s 5ms/step - loss: 3163421.0000 - val_loss: 2945074.5000\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 2945074.50000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff678360510>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jebvGjt_V-bm"
      },
      "source": [
        "# **Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVPWJ6ZFWCqb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1e2dbe1-127e-48ee-df3d-62b2226b2dcf"
      },
      "source": [
        "\n",
        "#compute hit rate for validation data\n",
        "predicted_app = model.predict(X_validation)\n",
        "idx = (-predicted_app).argsort() \n",
        "hit = 0\n",
        "for i in range(len(X_validation)):\n",
        "    if(Y_validation[i]== idx[i,0] or Y_validation[i]==idx[i,1] or Y_validation[i]==idx[i,2] or Y_validation[i]==idx[i,3] or Y_validation[i]==idx[i,5] ):\n",
        "        hit+=1 \n",
        "print(\"hit rate = \"+str(hit/len(X_validation)))\n",
        "\n",
        "# final result\n",
        "predicted_app_test = model.predict(X_test)\n",
        "idx = (-predicted_app_test).argsort() \n",
        "# write to file\n",
        "Point = make_dataclass(\"point\", [(\"id\", int), (\"next_games\", str)])\n",
        "answer = []\n",
        "for i in range(len(idx)):\n",
        "  # proper format\n",
        "  temp = \"\"\n",
        "  for j in range(5):\n",
        "    temp+= str(int(idx[i][j]))\n",
        "    if j != 4 :\n",
        "      temp += \" \"\n",
        "  answer.append(Point(index_test[i],temp))\n",
        "answer = pd.DataFrame(answer)\n",
        "answer.to_csv('/content/drive/MyDrive/Colab Notebooks/predict_next_game/result.csv')\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hit rate = 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}